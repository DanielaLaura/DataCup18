{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.size'] = 18\n",
    "%matplotlib inline\n",
    "\n",
    "# Governing choices for search\n",
    "N_FOLDS = 10\n",
    "MAX_EVALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (8900, 60)\n",
      "Test shape:  (3000, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_CurrentTotalBalance_count</th>\n",
       "      <th>fact_CurrentTotalBalance_mean</th>\n",
       "      <th>fact_CurrentTotalBalance_max</th>\n",
       "      <th>fact_CurrentTotalBalance_min</th>\n",
       "      <th>fact_CurrentTotalBalance_sum</th>\n",
       "      <th>fact_CurrentTotalBalance_skew</th>\n",
       "      <th>fact_CashBalance_count</th>\n",
       "      <th>fact_CashBalance_mean</th>\n",
       "      <th>fact_CashBalance_max</th>\n",
       "      <th>fact_CashBalance_min</th>\n",
       "      <th>...</th>\n",
       "      <th>('PRIOR_CREDIT_LIMIT_AMT', 'max')</th>\n",
       "      <th>('PRIOR_CREDIT_LIMIT_AMT', 'min')</th>\n",
       "      <th>('PRIOR_CREDIT_LIMIT_AMT', 'sum')</th>\n",
       "      <th>('PRIOR_CREDIT_LIMIT_AMT', 'skew')</th>\n",
       "      <th>('TRANSACTION_AMT', 'count')</th>\n",
       "      <th>('TRANSACTION_AMT', 'mean')</th>\n",
       "      <th>('TRANSACTION_AMT', 'max')</th>\n",
       "      <th>('TRANSACTION_AMT', 'min')</th>\n",
       "      <th>('TRANSACTION_AMT', 'sum')</th>\n",
       "      <th>('TRANSACTION_AMT', 'skew')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>14</td>\n",
       "      <td>1424.866429</td>\n",
       "      <td>3340.54</td>\n",
       "      <td>364.64</td>\n",
       "      <td>19948.13</td>\n",
       "      <td>0.854357</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>14</td>\n",
       "      <td>648.647143</td>\n",
       "      <td>1219.00</td>\n",
       "      <td>54.57</td>\n",
       "      <td>9081.06</td>\n",
       "      <td>-0.361304</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>14</td>\n",
       "      <td>6645.958571</td>\n",
       "      <td>13201.51</td>\n",
       "      <td>2022.48</td>\n",
       "      <td>93043.42</td>\n",
       "      <td>0.607540</td>\n",
       "      <td>14</td>\n",
       "      <td>60.770000</td>\n",
       "      <td>380.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>14</td>\n",
       "      <td>1194.207143</td>\n",
       "      <td>2013.94</td>\n",
       "      <td>472.94</td>\n",
       "      <td>16718.90</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>14</td>\n",
       "      <td>849.707143</td>\n",
       "      <td>975.20</td>\n",
       "      <td>562.57</td>\n",
       "      <td>11895.90</td>\n",
       "      <td>-1.504595</td>\n",
       "      <td>14</td>\n",
       "      <td>5.596429</td>\n",
       "      <td>46.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45924.0</td>\n",
       "      <td>1.303881</td>\n",
       "      <td>201.0</td>\n",
       "      <td>27.075622</td>\n",
       "      <td>469.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5442.2</td>\n",
       "      <td>4.928984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fact_CurrentTotalBalance_count  fact_CurrentTotalBalance_mean  \\\n",
       "10381                              14                    1424.866429   \n",
       "4960                               14                     648.647143   \n",
       "8163                               14                    6645.958571   \n",
       "7065                               14                    1194.207143   \n",
       "2987                               14                     849.707143   \n",
       "\n",
       "       fact_CurrentTotalBalance_max  fact_CurrentTotalBalance_min  \\\n",
       "10381                       3340.54                        364.64   \n",
       "4960                        1219.00                         54.57   \n",
       "8163                       13201.51                       2022.48   \n",
       "7065                        2013.94                        472.94   \n",
       "2987                         975.20                        562.57   \n",
       "\n",
       "       fact_CurrentTotalBalance_sum  fact_CurrentTotalBalance_skew  \\\n",
       "10381                      19948.13                       0.854357   \n",
       "4960                        9081.06                      -0.361304   \n",
       "8163                       93043.42                       0.607540   \n",
       "7065                       16718.90                       0.339380   \n",
       "2987                       11895.90                      -1.504595   \n",
       "\n",
       "       fact_CashBalance_count  fact_CashBalance_mean  fact_CashBalance_max  \\\n",
       "10381                      14               0.000000                  0.00   \n",
       "4960                       14               0.000000                  0.00   \n",
       "8163                       14              60.770000                380.10   \n",
       "7065                       14               0.000000                  0.00   \n",
       "2987                       14               5.596429                 46.35   \n",
       "\n",
       "       fact_CashBalance_min             ...               \\\n",
       "10381                   0.0             ...                \n",
       "4960                    0.0             ...                \n",
       "8163                    0.0             ...                \n",
       "7065                    0.0             ...                \n",
       "2987                    0.0             ...                \n",
       "\n",
       "       ('PRIOR_CREDIT_LIMIT_AMT', 'max')  ('PRIOR_CREDIT_LIMIT_AMT', 'min')  \\\n",
       "10381                                NaN                                NaN   \n",
       "4960                                 NaN                                NaN   \n",
       "8163                                 NaN                                NaN   \n",
       "7065                                 NaN                                NaN   \n",
       "2987                               625.0                               22.0   \n",
       "\n",
       "       ('PRIOR_CREDIT_LIMIT_AMT', 'sum')  ('PRIOR_CREDIT_LIMIT_AMT', 'skew')  \\\n",
       "10381                                NaN                                 NaN   \n",
       "4960                                 NaN                                 NaN   \n",
       "8163                                 NaN                                 NaN   \n",
       "7065                                 NaN                                 NaN   \n",
       "2987                             45924.0                            1.303881   \n",
       "\n",
       "       ('TRANSACTION_AMT', 'count')  ('TRANSACTION_AMT', 'mean')  \\\n",
       "10381                           NaN                          NaN   \n",
       "4960                            NaN                          NaN   \n",
       "8163                            NaN                          NaN   \n",
       "7065                            NaN                          NaN   \n",
       "2987                          201.0                    27.075622   \n",
       "\n",
       "       ('TRANSACTION_AMT', 'max')  ('TRANSACTION_AMT', 'min')  \\\n",
       "10381                         NaN                         NaN   \n",
       "4960                          NaN                         NaN   \n",
       "8163                          NaN                         NaN   \n",
       "7065                          NaN                         NaN   \n",
       "2987                        469.2                         0.0   \n",
       "\n",
       "       ('TRANSACTION_AMT', 'sum')  ('TRANSACTION_AMT', 'skew')  \n",
       "10381                         NaN                          NaN  \n",
       "4960                          NaN                          NaN  \n",
       "8163                          NaN                          NaN  \n",
       "7065                          NaN                          NaN  \n",
       "2987                       5442.2                     4.928984  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('train_good.csv')\n",
    "\n",
    "# Sample 16000 rows (10000 for training, 6000 for testing)\n",
    "features = features.sample(n = 11900, random_state = 42)\n",
    "\n",
    "# Only numeric features\n",
    "features = features.select_dtypes('number')\n",
    "\n",
    "# Extract the labels\n",
    "labels = np.array(features['Default'].astype(np.int32)).reshape((-1, ))\n",
    "features = features.drop(columns = ['Default', 'ID_CPTE'])\n",
    "\n",
    "# Split into training and testing data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 3000, random_state = 42)\n",
    "\n",
    "print('Train shape: ', train_features.shape)\n",
    "print('Test shape: ', test_features.shape)\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(random_state=50)\n",
    "\n",
    "# Training set\n",
    "train_set = lgb.Dataset(train_features, label = train_labels)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:657: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximium ROC AUC in cross validation was 0.88698 with std of 0.00852.\n",
      "The ideal number of iterations was 29.\n"
     ]
    }
   ],
   "source": [
    "# Default hyperparamters\n",
    "hyperparameters = model.get_params()\n",
    "\n",
    "# Using early stopping to determine number of estimators.\n",
    "del hyperparameters['n_estimators']\n",
    "\n",
    "# Perform cross validation with early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, metrics = 'auc', \n",
    "           early_stopping_rounds = 100, verbose_eval = False, seed = 42)\n",
    "\n",
    "# Highest score\n",
    "best = cv_results['auc-mean'][-1]\n",
    "\n",
    "# Standard deviation of best score\n",
    "best_std = cv_results['auc-stdv'][-1]\n",
    "\n",
    "print('The maximium ROC AUC in cross validation was {:.5f} with std of {:.5f}.'.format(best, best_std))\n",
    "print('The ideal number of iterations was {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can evaluate the baseline model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model scores 0.88282 ROC AUC on the test set.\n"
     ]
    }
   ],
   "source": [
    " #Optimal number of esimators found in cv\n",
    "model.n_estimators = len(cv_results['auc-mean'])\n",
    "\n",
    "# Train and make predicions with model\n",
    "model.fit(train_features, train_labels)\n",
    "preds = model.predict_proba(test_features)[:, 1]\n",
    "baseline_auc = roc_auc_score(test_labels, preds)\n",
    "\n",
    "print('The baseline model scores {:.5f} ROC AUC on the test set.'.format(baseline_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Domain\n",
    "\n",
    "Specifying the domain (called the space in Hyperopt) is a little trickier than in grid search. In Hyperopt, and other Bayesian optimization frameworks, the domian is not a discrete grid but instead has probability distributions for each hyperparameter. For each hyperparameter, we will use the same limits as with the grid, but instead of being defined at each point, the domain represents probabilities for each hyperparameter. This will probably become clearer in the code and the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the learning rate\n",
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGMCAYAAADHkOslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/8BxHG++2hFvXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate_dist = []\n",
    "\n",
    "# Draw 10000 samples from the learning rate domain\n",
    "for _ in range(7900):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\n",
    "plt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGMCAYAAACh/GqDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJdYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discrete uniform distribution\n",
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "# Sample 10000 times from the number of leaves distribution\n",
    "for _ in range(7900):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "# kdeplot\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\n",
    "plt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Conditional Domain\n",
    "In Hyperopt, we can use nested conditional statements to indicate hyperparameters that depend on other hyperparameters. For example, the \"goss\" boosting_type cannot use subsampling, so when we set up the boosting_type categorical variable, we have to set the subsample to 1.0 while for the other boosting types it's a float between 0.5 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'goss', 'subsample': 1.0}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boosting type domain \n",
    "boosting_type = {'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n",
    "\n",
    "# Draw a sample\n",
    "hyperparams = sample(boosting_type)\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to set both the boosting_type and subsample as top-level keys in the parameter dictionary. We can use the Python dict.get method with a default value of 1.0. This means that if the key is not present in the dictionary, the value returned will be the default (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss', 'subsample': 1.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the subsample if present otherwise set to 1.0\n",
    "subsample = hyperparams['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Extract the boosting type\n",
    "hyperparams['boosting_type'] = hyperparams['boosting_type']['boosting_type']\n",
    "hyperparams['subsample'] = subsample\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The gbm cannot use the nested dictionary so we need to set the boosting_type and subsample as top level keys.\n",
    "\n",
    "Nested conditionals allow us to use a different set of hyperparameters depending on other hyperparameters. For example, we can explore different models with completely different sets of hyperparameters by using nested conditionals. The only requirement is that the first nested statement must be based on a choice hyperparameter (the choice could be the type of model).\n",
    "\n",
    "### Complete Bayesian Domain\n",
    "\n",
    "Now we can define the entire domain. Each variable needs to have a label and a few parameters specifying the type and extent of the distribution. For the variables such as boosting type that are categorical, we use the choice variable. Other variables types include quniform, loguniform, and uniform. For the complete list, check out the documentation for Hyperopt. Altogether there are 10 hyperparameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Example of Sampling from the Domain\n",
    "Let's sample from the domain (using the conditional logic) to see the result of each draw. Every time we run this code, the results will change. (Again notice that we need to assign the top level keys to the keywords understood by the GBM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.9252938188014599,\n",
       " 'is_unbalance': False,\n",
       " 'learning_rate': 0.03777302613386964,\n",
       " 'min_child_samples': 200.0,\n",
       " 'num_leaves': 138.0,\n",
       " 'reg_alpha': 0.6927228103324505,\n",
       " 'reg_lambda': 0.18207869731617476,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 100000.0}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from the full space\n",
    "x = sample(space)\n",
    "\n",
    "# Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.6321276859520862,\n",
       " 'is_unbalance': False,\n",
       " 'learning_rate': 0.030957593776215753,\n",
       " 'min_child_samples': 55.0,\n",
       " 'num_leaves': 109.0,\n",
       " 'reg_alpha': 0.5815123237458364,\n",
       " 'reg_lambda': 0.8183893826118409,\n",
       " 'subsample': 0.8905510555126552,\n",
       " 'subsample_for_bin': 200000.0}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's test the objective function with the domain to make sure it works. (Every time the of_connection line is run, the outfile will be overwritten, so use a different name for each trial to save the results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation loss = 0.10722.\n",
      "The optimal number of estimators was 329.\n"
     ]
    }
   ],
   "source": [
    "# Create a new file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n",
    "\n",
    "# Test the objective function\n",
    "results = objective(sample(space))\n",
    "print('The cross validation loss = {:.5f}.'.format(results['loss']))\n",
    "print('The optimal number of estimators was {}.'.format(results['hyperparameters']['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization Algorithm\n",
    "\n",
    "The optimization algorithm is the method for constructing the surrogate function (probability model) and selecting the next set of hyperparameters to evaluate in the objective function. Hyperopt has two choices: random search and Tree Parzen Estimator.\n",
    "\n",
    "The technical details of TPE can be found in this article and a conceptual explanation is in this article. Although this is the most technical part of Bayesian hyperparameter optimization, defining the algorithm in Hyperopt is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# Record results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Trials object will hold everything returned from the objective function in the .results attribute. We can use this after the search is complete to inspect the results, but an easier method is to read in the csv file because that will already be in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Automated Hyperparameter Optimization in Practice\n",
    "\n",
    "We have all four parts we need to run the optimization. To run Bayesian optimization we use the fmin function (a good reminder that we need a metric to minimize!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "fmin takes the four parts defined above as well as the maximum number of iterations max_evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 1,\n",
       " 'colsample_by_tree': 0.991304678949413,\n",
       " 'dart_subsample': 0.8090820541658564,\n",
       " 'is_unbalance': 1,\n",
       " 'learning_rate': 0.03756977692658773,\n",
       " 'min_child_samples': 350.0,\n",
       " 'num_leaves': 67.0,\n",
       " 'reg_alpha': 0.5073057282312433,\n",
       " 'reg_lambda': 0.3338005245605391,\n",
       " 'subsample_for_bin': 260000.0}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(OUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The function below takes in the results, trains a model on the training data, and evalutes on the testing data. It returns a dataframe of hyperparameters from the search.\n",
    "\n",
    "Saving the results to a csv file converts the dictionary of hyperparameters to a string. We need to map this back to a dictionary using ast.literal_eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def evaluate(results, name):\n",
    "    \"\"\"Evaluate model on test data using hyperparameters in results\n",
    "       Return dataframe of hyperparameters\"\"\"\n",
    "    \n",
    "    new_results = results.copy()\n",
    "    # String to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "    \n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    model = lgb.LGBMClassifier(**hyperparameters)\n",
    "    \n",
    "    # Train and make predictions\n",
    "    model.fit(train_features, train_labels)\n",
    "    preds = model.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(test_labels, preds)))\n",
    "    \n",
    "    # Create dataframe of hyperparameters\n",
    "    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n",
    "\n",
    "    # Iterate through each set of hyperparameters that were evaluated\n",
    "    for i, hyp in enumerate(new_results['hyperparameters']):\n",
    "        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = new_results['iteration']\n",
    "    hyp_df['score'] = new_results['score']\n",
    "    \n",
    "    return hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from Bayesian was 0.89217 found on iteration 4.\n",
      "ROC AUC from Bayesian on test data = 0.89041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample</th>\n",
       "      <th>metric</th>\n",
       "      <th>verbose</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.991305</td>\n",
       "      <td>False</td>\n",
       "      <td>0.037570</td>\n",
       "      <td>350</td>\n",
       "      <td>67</td>\n",
       "      <td>0.507306</td>\n",
       "      <td>0.333801</td>\n",
       "      <td>260000</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>0.892166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.751996</td>\n",
       "      <td>True</td>\n",
       "      <td>0.068830</td>\n",
       "      <td>415</td>\n",
       "      <td>51</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>0.414021</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.684527</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>5</td>\n",
       "      <td>0.891511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.658184</td>\n",
       "      <td>False</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>110</td>\n",
       "      <td>49</td>\n",
       "      <td>0.534057</td>\n",
       "      <td>0.702573</td>\n",
       "      <td>180000</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>8</td>\n",
       "      <td>0.891016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.818157</td>\n",
       "      <td>False</td>\n",
       "      <td>0.108565</td>\n",
       "      <td>455</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.171773</td>\n",
       "      <td>220000</td>\n",
       "      <td>0.582428</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.843663</td>\n",
       "      <td>True</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>145</td>\n",
       "      <td>137</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.511729</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.718266</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>0.889579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.625506</td>\n",
       "      <td>True</td>\n",
       "      <td>0.057830</td>\n",
       "      <td>20</td>\n",
       "      <td>61</td>\n",
       "      <td>0.205188</td>\n",
       "      <td>0.532582</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.821439</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.722398</td>\n",
       "      <td>True</td>\n",
       "      <td>0.150741</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>0.665232</td>\n",
       "      <td>0.560429</td>\n",
       "      <td>40000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.993068</td>\n",
       "      <td>True</td>\n",
       "      <td>0.162786</td>\n",
       "      <td>280</td>\n",
       "      <td>35</td>\n",
       "      <td>0.471720</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>280000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.879790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.809665</td>\n",
       "      <td>False</td>\n",
       "      <td>0.085799</td>\n",
       "      <td>460</td>\n",
       "      <td>54</td>\n",
       "      <td>0.285526</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>40000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>goss</td>\n",
       "      <td>0.659665</td>\n",
       "      <td>True</td>\n",
       "      <td>0.344239</td>\n",
       "      <td>455</td>\n",
       "      <td>126</td>\n",
       "      <td>0.286126</td>\n",
       "      <td>0.054387</td>\n",
       "      <td>200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>auc</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.869787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type  colsample_bytree is_unbalance  learning_rate  \\\n",
       "0          dart          0.991305        False       0.037570   \n",
       "1          dart          0.751996         True       0.068830   \n",
       "2          dart          0.658184        False       0.022836   \n",
       "3          gbdt          0.818157        False       0.108565   \n",
       "4          gbdt          0.843663         True       0.055458   \n",
       "5          dart          0.625506         True       0.057830   \n",
       "6          goss          0.722398         True       0.150741   \n",
       "7          goss          0.993068         True       0.162786   \n",
       "8          goss          0.809665        False       0.085799   \n",
       "9          goss          0.659665         True       0.344239   \n",
       "\n",
       "  min_child_samples num_leaves  reg_alpha  reg_lambda subsample_for_bin  \\\n",
       "0               350         67   0.507306    0.333801            260000   \n",
       "1               415         51   0.990971    0.414021            120000   \n",
       "2               110         49   0.534057    0.702573            180000   \n",
       "3               455         47   0.347243    0.171773            220000   \n",
       "4               145        137   0.230731    0.511729            100000   \n",
       "5                20         61   0.205188    0.532582            200000   \n",
       "6                95         85   0.665232    0.560429             40000   \n",
       "7               280         35   0.471720    0.023881            280000   \n",
       "8               460         54   0.285526    0.593218             40000   \n",
       "9               455        126   0.286126    0.054387            200000   \n",
       "\n",
       "   subsample metric verbose n_estimators  iteration     score  \n",
       "0   0.809082    auc       1          618          4  0.892166  \n",
       "1   0.684527    auc       1          413          5  0.891511  \n",
       "2   0.985067    auc       1          441          8  0.891016  \n",
       "3   0.582428    auc       1           89          1  0.890348  \n",
       "4   0.718266    auc       1           52          6  0.889579  \n",
       "5   0.821439    auc       1          167          2  0.888192  \n",
       "6   1.000000    auc       1            6         10  0.885587  \n",
       "7   1.000000    auc       1            6          9  0.879790  \n",
       "8   1.000000    auc       1           11          3  0.875136  \n",
       "9   1.000000    auc       1            2          7  0.869787  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_results = evaluate(results, name = 'Bayesian')\n",
    "bayes_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " MAX_EVALS = 5\n",
    "\n",
    "# # Create a new file and open a connection\n",
    "OUT_FILE = 'bayesian_trials_500.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# # Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n",
    "\n",
    "# # Record results\n",
    "trials = Trials()\n",
    "\n",
    "global ITERATION\n",
    "\n",
    "ITERATION = 0 \n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest,\n",
    "             trials = trials, max_evals = MAX_EVALS)\n",
    "\n",
    "# # Sort the trials with lowest loss (highest AUC) first\n",
    "trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n",
    "\n",
    "print('Finished, best results')\n",
    "print(trials_dict[:1])\n",
    "\n",
    "# # Save the trial results\n",
    "with open('trials500.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the trial results\n",
    "with open('trials500.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (11900, 60)\n",
      "Testing shape:  (5100, 60)\n"
     ]
    }
   ],
   "source": [
    "# Read in full dataset\n",
    "train = pd.read_csv('train_good.csv')\n",
    "test = pd.read_csv('test_good.csv')\n",
    "train = train.drop(columns = ['AssessmentPeriod'])\n",
    "test = test.drop(columns = ['AssessmentPeriod'])\n",
    "# Extract the test ids and train labels\n",
    "test_ids = test['ID_CPTE']\n",
    "train_labels = np.array(train['Default'].astype(np.int32)).reshape((-1, ))\n",
    "\n",
    "train = train.drop(columns = ['ID_CPTE', 'Default'])\n",
    "test = test.drop(columns = ['ID_CPTE'])\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bayes_results = pd.read_csv('bayesian_trials_500.csv').sort_values('score', ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from Bayesian was 0.89275 found on iteration 96.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "b'len of label is not same with #data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-15ddfb46b119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbayes_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayes_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Bayesian'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-72681e27024a>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(results, name)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Train and make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    673\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1301\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1303\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot initialize Dataset from {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label should not be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mset_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_to_1d_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_field\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mset_field\u001b[1;34m(self, field_name, data)\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mptr_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m             ctypes.c_int(type_data)))\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_field\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: b'len of label is not same with #data'"
     ]
    }
   ],
   "source": [
    "bayes_params = evaluate(bayes_results, name = 'Bayesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-6e60f66ef897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'ROC AUC'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbayes_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iteration'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbayes_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iteration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'search'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Bayesian'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "scores = scores.append(pd.DataFrame({'ROC AUC': bayes_params['score'], 'iteration': bayes_params['iteration'], 'search': 'Bayesian'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bayes_results['hyperparameters'] = bayes_results['hyperparameters'].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation score on the full dataset for Bayesian optimization = 0.89275 with std: 0.00842.\n",
      "Number of estimators = 507.\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = dict(**bayes_results.loc[0, 'hyperparameters'])\n",
    "del hyperparameters['n_estimators']\n",
    "\n",
    "# Cross validation with n_folds and early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set,\n",
    "                    num_boost_round = 10000, early_stopping_rounds = 100, \n",
    "                    metrics = 'auc', nfold = N_FOLDS)\n",
    "\n",
    "print('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n",
    "    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "print('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "preds = model.predict_proba(test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'ID_CPTE': test_ids, 'Default': preds})\n",
    "submission.to_csv('submission_bayesian_optimization.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'num_row'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-cf9ef4519d2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m cv_results = xgb.cv(hyperparameters, train_set,\n\u001b[0;32m      7\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     metrics = 'auc', nfold = N_FOLDS)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m print('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     cvfolds = mknfold(dtrain, nfold, params, seed, metrics, fpreproc,\n\u001b[1;32m--> 376\u001b[1;33m                       stratified, folds, shuffle)\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;31m# setup callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mmknfold\u001b[1;34m(dall, nfold, param, seed, evals, fpreproc, stratified, folds, shuffle)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratified\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'num_row'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "hyperparameters = dict(**bayes_results.loc[0, 'hyperparameters'])\n",
    "del hyperparameters['n_estimators']\n",
    "\n",
    "# Cross validation with n_folds and early stopping\n",
    "cv_results = xgb.cv(hyperparameters, train_set,\n",
    "                    num_boost_round = 10000, early_stopping_rounds = 100, \n",
    "                    metrics = 'auc', nfold = N_FOLDS)\n",
    "\n",
    "print('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n",
    "    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "print('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='dart',\n",
       "       colsample_bylevel=1, colsample_bytree=0.6251259427191308, gamma=0,\n",
       "       is_unbalance=False, learning_rate=0.03946831148853219,\n",
       "       max_delta_step=0, max_depth=3, metric='auc', min_child_samples=305,\n",
       "       min_child_weight=1, missing=None, n_estimators=507, n_jobs=1,\n",
       "       nthread=None, num_leaves=144, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0.5358601896438846,\n",
       "       reg_lambda=0.4362156206217483, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.7593033982702072, subsample_for_bin=260000,\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\n",
    "model_xgb.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['fact_CurrentTotalBalance_count', 'fact_CurrentTotalBalance_mean', 'fact_CurrentTotalBalance_max', 'fact_CurrentTotalBalance_min', 'fact_CurrentTotalBalance_sum', 'fact_CurrentTotalBalance_skew', 'fact_CashBalance_count', 'fact_CashBalance_mean', 'fact_CashBalance_max', 'fact_CashBalance_min', 'fact_CashBalance_sum', 'fact_CashBalance_skew', 'fact_CreditLimit_count', 'fact_CreditLimit_mean', 'fact_CreditLimit_max', 'fact_CreditLimit_min', 'fact_CreditLimit_sum', 'fact_CreditLimit_skew', 'fact_DelqCycle_count', 'fact_DelqCycle_mean', 'fact_DelqCycle_max', 'fact_DelqCycle_min', 'fact_DelqCycle_sum', 'fact_DelqCycle_skew', 'fact_Owning_count', 'fact_Owning_mean', 'fact_Owning_max', 'fact_Owning_min', 'fact_Owning_sum', 'fact_Owning_skew', 'fact_CreditLeft_count', 'fact_CreditLeft_mean', 'fact_CreditLeft_max', 'fact_CreditLeft_min', 'fact_CreditLeft_sum', 'fact_CreditLeft_skew', 'fact_CashRatio_count', 'fact_CashRatio_mean', 'fact_CashRatio_max', 'fact_CashRatio_min', 'fact_CashRatio_sum', 'fact_CashRatio_skew', \"('AmountPaid', 'count')\", \"('AmountPaid', 'mean')\", \"('AmountPaid', 'max')\", \"('AmountPaid', 'min')\", \"('AmountPaid', 'sum')\", \"('AmountPaid', 'skew')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'count')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'mean')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'max')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'min')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'sum')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'skew')\", \"('TRANSACTION_AMT', 'count')\", \"('TRANSACTION_AMT', 'mean')\", \"('TRANSACTION_AMT', 'max')\", \"('TRANSACTION_AMT', 'min')\", \"('TRANSACTION_AMT', 'sum')\", \"('TRANSACTION_AMT', 'skew')\"] [\"('CurrentTotalBalance', 'count')\", \"('CurrentTotalBalance', 'mean')\", \"('CurrentTotalBalance', 'max')\", \"('CurrentTotalBalance', 'min')\", \"('CurrentTotalBalance', 'sum')\", \"('CurrentTotalBalance', 'skew')\", \"('CashBalance', 'count')\", \"('CashBalance', 'mean')\", \"('CashBalance', 'max')\", \"('CashBalance', 'min')\", \"('CashBalance', 'sum')\", \"('CashBalance', 'skew')\", \"('CreditLimit', 'count')\", \"('CreditLimit', 'mean')\", \"('CreditLimit', 'max')\", \"('CreditLimit', 'min')\", \"('CreditLimit', 'sum')\", \"('CreditLimit', 'skew')\", \"('DelqCycle', 'count')\", \"('DelqCycle', 'mean')\", \"('DelqCycle', 'max')\", \"('DelqCycle', 'min')\", \"('DelqCycle', 'sum')\", \"('DelqCycle', 'skew')\", \"('Owning', 'count')\", \"('Owning', 'mean')\", \"('Owning', 'max')\", \"('Owning', 'min')\", \"('Owning', 'sum')\", \"('Owning', 'skew')\", \"('CreditLeft', 'count')\", \"('CreditLeft', 'mean')\", \"('CreditLeft', 'max')\", \"('CreditLeft', 'min')\", \"('CreditLeft', 'sum')\", \"('CreditLeft', 'skew')\", \"('CashRatio', 'count')\", \"('CashRatio', 'mean')\", \"('CashRatio', 'max')\", \"('CashRatio', 'min')\", \"('CashRatio', 'sum')\", \"('CashRatio', 'skew')\", \"('AmountPaid', 'count')\", \"('AmountPaid', 'mean')\", \"('AmountPaid', 'max')\", \"('AmountPaid', 'min')\", \"('AmountPaid', 'sum')\", \"('AmountPaid', 'skew')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'count')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'mean')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'max')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'min')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'sum')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'skew')\", \"('TRANSACTION_AMT', 'count')\", \"('TRANSACTION_AMT', 'mean')\", \"('TRANSACTION_AMT', 'max')\", \"('TRANSACTION_AMT', 'min')\", \"('TRANSACTION_AMT', 'sum')\", \"('TRANSACTION_AMT', 'skew')\"]\nexpected fact_CashBalance_min, fact_CashRatio_max, fact_CreditLimit_max, fact_DelqCycle_mean, fact_CreditLeft_max, fact_Owning_min, fact_CurrentTotalBalance_max, fact_CreditLimit_sum, fact_CashBalance_skew, fact_CurrentTotalBalance_min, fact_CreditLeft_skew, fact_CashBalance_sum, fact_CurrentTotalBalance_count, fact_CreditLimit_skew, fact_CreditLeft_mean, fact_CashBalance_count, fact_CurrentTotalBalance_mean, fact_CreditLimit_min, fact_DelqCycle_skew, fact_CashRatio_skew, fact_DelqCycle_min, fact_CashBalance_mean, fact_Owning_skew, fact_CreditLimit_mean, fact_CreditLeft_count, fact_CreditLeft_sum, fact_Owning_max, fact_CashRatio_sum, fact_DelqCycle_sum, fact_CreditLimit_count, fact_CurrentTotalBalance_skew, fact_DelqCycle_max, fact_CurrentTotalBalance_sum, fact_Owning_count, fact_CashRatio_mean, fact_CashBalance_max, fact_Owning_sum, fact_CashRatio_count, fact_CreditLeft_min, fact_CashRatio_min, fact_DelqCycle_count, fact_Owning_mean in input data\ntraining data did not have the following fields: ('CreditLimit', 'min'), ('CashBalance', 'max'), ('CurrentTotalBalance', 'sum'), ('CurrentTotalBalance', 'mean'), ('CreditLeft', 'skew'), ('CashRatio', 'skew'), ('CreditLimit', 'skew'), ('CurrentTotalBalance', 'min'), ('DelqCycle', 'mean'), ('CashRatio', 'max'), ('CashRatio', 'mean'), ('Owning', 'count'), ('Owning', 'mean'), ('CashRatio', 'sum'), ('DelqCycle', 'count'), ('DelqCycle', 'skew'), ('DelqCycle', 'max'), ('CashBalance', 'count'), ('CreditLeft', 'mean'), ('Owning', 'sum'), ('CurrentTotalBalance', 'skew'), ('CashBalance', 'mean'), ('CreditLimit', 'mean'), ('CurrentTotalBalance', 'count'), ('CashRatio', 'count'), ('CreditLimit', 'sum'), ('CreditLeft', 'count'), ('CashBalance', 'skew'), ('CashBalance', 'min'), ('CreditLeft', 'sum'), ('Owning', 'min'), ('DelqCycle', 'sum'), ('CreditLeft', 'min'), ('CashRatio', 'min'), ('Owning', 'max'), ('Owning', 'skew'), ('CreditLeft', 'max'), ('CashBalance', 'sum'), ('CreditLimit', 'count'), ('DelqCycle', 'min'), ('CurrentTotalBalance', 'max'), ('CreditLimit', 'max')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-6851b0754a34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'ID_CPTE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Default'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission_bayesian_optimizatio3.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    573\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0;32m    574\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi:softprob\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[0moption_mask\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[1;36m0x10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1308\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['fact_CurrentTotalBalance_count', 'fact_CurrentTotalBalance_mean', 'fact_CurrentTotalBalance_max', 'fact_CurrentTotalBalance_min', 'fact_CurrentTotalBalance_sum', 'fact_CurrentTotalBalance_skew', 'fact_CashBalance_count', 'fact_CashBalance_mean', 'fact_CashBalance_max', 'fact_CashBalance_min', 'fact_CashBalance_sum', 'fact_CashBalance_skew', 'fact_CreditLimit_count', 'fact_CreditLimit_mean', 'fact_CreditLimit_max', 'fact_CreditLimit_min', 'fact_CreditLimit_sum', 'fact_CreditLimit_skew', 'fact_DelqCycle_count', 'fact_DelqCycle_mean', 'fact_DelqCycle_max', 'fact_DelqCycle_min', 'fact_DelqCycle_sum', 'fact_DelqCycle_skew', 'fact_Owning_count', 'fact_Owning_mean', 'fact_Owning_max', 'fact_Owning_min', 'fact_Owning_sum', 'fact_Owning_skew', 'fact_CreditLeft_count', 'fact_CreditLeft_mean', 'fact_CreditLeft_max', 'fact_CreditLeft_min', 'fact_CreditLeft_sum', 'fact_CreditLeft_skew', 'fact_CashRatio_count', 'fact_CashRatio_mean', 'fact_CashRatio_max', 'fact_CashRatio_min', 'fact_CashRatio_sum', 'fact_CashRatio_skew', \"('AmountPaid', 'count')\", \"('AmountPaid', 'mean')\", \"('AmountPaid', 'max')\", \"('AmountPaid', 'min')\", \"('AmountPaid', 'sum')\", \"('AmountPaid', 'skew')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'count')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'mean')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'max')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'min')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'sum')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'skew')\", \"('TRANSACTION_AMT', 'count')\", \"('TRANSACTION_AMT', 'mean')\", \"('TRANSACTION_AMT', 'max')\", \"('TRANSACTION_AMT', 'min')\", \"('TRANSACTION_AMT', 'sum')\", \"('TRANSACTION_AMT', 'skew')\"] [\"('CurrentTotalBalance', 'count')\", \"('CurrentTotalBalance', 'mean')\", \"('CurrentTotalBalance', 'max')\", \"('CurrentTotalBalance', 'min')\", \"('CurrentTotalBalance', 'sum')\", \"('CurrentTotalBalance', 'skew')\", \"('CashBalance', 'count')\", \"('CashBalance', 'mean')\", \"('CashBalance', 'max')\", \"('CashBalance', 'min')\", \"('CashBalance', 'sum')\", \"('CashBalance', 'skew')\", \"('CreditLimit', 'count')\", \"('CreditLimit', 'mean')\", \"('CreditLimit', 'max')\", \"('CreditLimit', 'min')\", \"('CreditLimit', 'sum')\", \"('CreditLimit', 'skew')\", \"('DelqCycle', 'count')\", \"('DelqCycle', 'mean')\", \"('DelqCycle', 'max')\", \"('DelqCycle', 'min')\", \"('DelqCycle', 'sum')\", \"('DelqCycle', 'skew')\", \"('Owning', 'count')\", \"('Owning', 'mean')\", \"('Owning', 'max')\", \"('Owning', 'min')\", \"('Owning', 'sum')\", \"('Owning', 'skew')\", \"('CreditLeft', 'count')\", \"('CreditLeft', 'mean')\", \"('CreditLeft', 'max')\", \"('CreditLeft', 'min')\", \"('CreditLeft', 'sum')\", \"('CreditLeft', 'skew')\", \"('CashRatio', 'count')\", \"('CashRatio', 'mean')\", \"('CashRatio', 'max')\", \"('CashRatio', 'min')\", \"('CashRatio', 'sum')\", \"('CashRatio', 'skew')\", \"('AmountPaid', 'count')\", \"('AmountPaid', 'mean')\", \"('AmountPaid', 'max')\", \"('AmountPaid', 'min')\", \"('AmountPaid', 'sum')\", \"('AmountPaid', 'skew')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'count')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'mean')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'max')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'min')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'sum')\", \"('PRIOR_CREDIT_LIMIT_AMT', 'skew')\", \"('TRANSACTION_AMT', 'count')\", \"('TRANSACTION_AMT', 'mean')\", \"('TRANSACTION_AMT', 'max')\", \"('TRANSACTION_AMT', 'min')\", \"('TRANSACTION_AMT', 'sum')\", \"('TRANSACTION_AMT', 'skew')\"]\nexpected fact_CashBalance_min, fact_CashRatio_max, fact_CreditLimit_max, fact_DelqCycle_mean, fact_CreditLeft_max, fact_Owning_min, fact_CurrentTotalBalance_max, fact_CreditLimit_sum, fact_CashBalance_skew, fact_CurrentTotalBalance_min, fact_CreditLeft_skew, fact_CashBalance_sum, fact_CurrentTotalBalance_count, fact_CreditLimit_skew, fact_CreditLeft_mean, fact_CashBalance_count, fact_CurrentTotalBalance_mean, fact_CreditLimit_min, fact_DelqCycle_skew, fact_CashRatio_skew, fact_DelqCycle_min, fact_CashBalance_mean, fact_Owning_skew, fact_CreditLimit_mean, fact_CreditLeft_count, fact_CreditLeft_sum, fact_Owning_max, fact_CashRatio_sum, fact_DelqCycle_sum, fact_CreditLimit_count, fact_CurrentTotalBalance_skew, fact_DelqCycle_max, fact_CurrentTotalBalance_sum, fact_Owning_count, fact_CashRatio_mean, fact_CashBalance_max, fact_Owning_sum, fact_CashRatio_count, fact_CreditLeft_min, fact_CashRatio_min, fact_DelqCycle_count, fact_Owning_mean in input data\ntraining data did not have the following fields: ('CreditLimit', 'min'), ('CashBalance', 'max'), ('CurrentTotalBalance', 'sum'), ('CurrentTotalBalance', 'mean'), ('CreditLeft', 'skew'), ('CashRatio', 'skew'), ('CreditLimit', 'skew'), ('CurrentTotalBalance', 'min'), ('DelqCycle', 'mean'), ('CashRatio', 'max'), ('CashRatio', 'mean'), ('Owning', 'count'), ('Owning', 'mean'), ('CashRatio', 'sum'), ('DelqCycle', 'count'), ('DelqCycle', 'skew'), ('DelqCycle', 'max'), ('CashBalance', 'count'), ('CreditLeft', 'mean'), ('Owning', 'sum'), ('CurrentTotalBalance', 'skew'), ('CashBalance', 'mean'), ('CreditLimit', 'mean'), ('CurrentTotalBalance', 'count'), ('CashRatio', 'count'), ('CreditLimit', 'sum'), ('CreditLeft', 'count'), ('CashBalance', 'skew'), ('CashBalance', 'min'), ('CreditLeft', 'sum'), ('Owning', 'min'), ('DelqCycle', 'sum'), ('CreditLeft', 'min'), ('CashRatio', 'min'), ('Owning', 'max'), ('Owning', 'skew'), ('CreditLeft', 'max'), ('CashBalance', 'sum'), ('CreditLimit', 'count'), ('DelqCycle', 'min'), ('CurrentTotalBalance', 'max'), ('CreditLimit', 'max')"
     ]
    }
   ],
   "source": [
    "preds = model_xgb.predict_proba(test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'ID_CPTE': test_ids, 'Default': preds})\n",
    "submission.to_csv('submission_bayesian_optimizatio3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
